---
layout: sidepanel
sidepanel: true
title: "Failures of Recognition"
nav_exclude: true
---

## Failures of recognition:
- [Gender bias and stereotypes in Large Language Models](https://dl.acm.org/doi/fullHtml/10.1145/3582269.3615599)
- [Generative AI Takes Stereotypes and Bias From Bad to Worse ](https://www.bloomberg.com/graphics/2023-generative-ai-bias/)
- [Algorithms of Oppression: How Search Engines Reinforce Racism ](https://www.jstor.org/stable/j.ctt1pwt9w5)
- [Reverse Engineering the Gendered Design of Amazonâ€™s Alexa: Methods in Testing Closed-Source Code in Grey and Black Box Systems](https://digitalhumanities.org/dhq/vol/17/2/000700/000700.html)
- <a href="https://jods.mitpress.mit.edu/pub/costanza-chock/release/4" target="_blank" style="text-decoration: underline;">Reducing biased and harmful outcomes in generative AI 
Design Justice, A.I., and Escape from the Matrix of Domination</a>
