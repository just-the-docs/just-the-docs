name: Check Nightly Build Status
on:
  workflow_call:
    inputs:
      event:
        type: string
      should_publish:
        type: string
  workflow_dispatch:
    inputs:
      event:
        description: event triggered the run (repository_dispatch - for `main`)
        type: string
      should_publish:
        description: true - to publish the report
        type: string

permissions:
  contents: write
  issues: write

concurrency:
  group: status-${{ github.workflow }}-${{ github.ref_name }}
  cancel-in-progress: false

env:
  GH_TOKEN: ${{ github.token }}
  GH_REPO: duckdb/duckdb
  GH_ISSUE_REPO: ${{ github.repository }}

jobs:
  get-run-info:
    name: Generate nightly build artifact json file
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}
      AWS_DEFAULT_REGION: us-east-2
    outputs:
      CURR_DATE: ${{ steps.curr-date.outputs.CURR_DATE }}
      matrix: ${{ steps.set-outputs.outputs.matrix }}
      run_id: ${{ steps.get_run_id.outputs.run_id }}
    steps:
      - id: curr-date
        run: echo "CURR_DATE=$(date +%Y-%m-%d)" >> $GITHUB_OUTPUT

      - name: Checkout repo with the script
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository_owner }}/duckdb-build-status

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
            python-version: '3.11'

      - name: Install DuckDB for Python
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install duckdb
      
      - name: Create Tables and Generate inputs.json
        shell: bash
        id: get_run_id
        env:
          CURR_DATE: ${{ steps.curr-date.outputs.CURR_DATE }}
        run: |
          run_id=$(python scripts/create_tables_and_inputs.py --branch "${{ github.ref_name }}" --event "${{ inputs.event }}")
          echo "run_id=$run_id" >> $GITHUB_OUTPUT

      - name: Upload DuckDB file
        uses: actions/upload-artifact@v4
        with:
          name: ${{ github.ref_name }}_run_info_tables.duckdb
          path: ${{ github.ref_name }}_run_info_tables.duckdb
      
      - name: Upload inputs_${{ github.ref_name }}.json
        uses: actions/upload-artifact@v4
        with:
          name: inputs_${{ github.ref_name }}.json
          path: inputs_${{ github.ref_name }}.json
          if-no-files-found: ignore

      - name: Read JSON and create matrix
        id: set-outputs
        run: |
          matrix=$(cat inputs_${{ github.ref_name }}.json | jq -c '.')
          echo "matrix=$matrix" >> $GITHUB_OUTPUT
          echo "***"
          cat inputs_${{ github.ref_name }}.json

  run-tests:
    name: ${{ matrix.config.branch }} - ${{ matrix.config.nightly_build }} ${{ matrix.config.duckdb_arch }} (${{ matrix.config.runs_on }})
    needs: 
      - get-run-info
    if: ${{ fromJson(needs.get-run-info.outputs.matrix) != '[]' }}
    strategy:
      matrix:
        config: ${{ fromJson(needs.get-run-info.outputs.matrix) }}
    continue-on-error: true
    runs-on: ${{ matrix.config.runs_on }}
    steps:
      - run: echo ${{ matrix.config.branch }} ${{ matrix.config.nightly_build }} ${{ matrix.config.runs_on }} ${{ matrix.config.duckdb_arch }} 
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
            python-version: '3.11'

      - name: Install Python dependencies
        run: pip install duckdb docker
            
      - name: Checkout repo with the scripts
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository_owner }}/duckdb-build-status

      - name: Checkout repo with extensions config file
        uses: actions/checkout@v4
        with:
            sparse-checkout: |
                .github/config
            path: ext
            repository: ${{ env.GH_REPO }}
            
      - name: Verify ${{ matrix.config.nightly_build }} ${{ matrix.config.duckdb_arch }} build version and Test extensions
        id: verify-build
        shell: bash
        env:
          CURR_DATE: ${{ needs.get-run-info.outputs.CURR_DATE }}
        run: |
            if [[ ${{ matrix.config.nightly_build }} != 'python' ]]; then
              echo "Downloading duckdb-binaries-${{ matrix.config.duckdb_binary }} artifact from ${{ matrix.config.run_id }}..."
              if gh run download ${{ matrix.config.run_id }} --repo ${{ env.GH_REPO }} -n duckdb-binaries-${{ matrix.config.duckdb_binary }}; then
                # echo "Artifact duckdb-binaries-${{ matrix.config.duckdb_binary }} is successfuly downloaded."
                if [[ ${{ matrix.config.nightly_build }} == 'osx' ]]; then
                  unzip duckdb_cli-*.zip -d duckdb_path
                else
                  if [[ ${{ matrix.config.branch }} != 'main' && ${{ matrix.config.nightly_build }} == 'linux' ]]; then
                    unzip duckdb_cli-${{ matrix.config.nightly_build }}-${{ matrix.config.duckdb_arch }}.zip -d duckdb_path
                  else
                    unzip duckdb_cli-${{ matrix.config.duckdb_binary }}.zip -d duckdb_path
                  fi
                fi
              fi
            fi
            echo "Verifying version and testing extensions..."
            python scripts/verify_and_test.py \
                --nightly_build ${{ matrix.config.nightly_build }} \
                --architecture ${{ matrix.config.duckdb_arch }} \
                --run_id ${{ matrix.config.run_id }} \
                --runs_on ${{ matrix.config.runs_on }} \
                --branch ${{ matrix.config.branch }}

      - name: Upload actions for extensions
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.config.branch }}_ext_${{ matrix.config.nightly_build }}_${{ matrix.config.duckdb_arch }}
          path: |
            ${{ matrix.config.branch }}_list_failed_ext_${{ matrix.config.nightly_build }}_${{ matrix.config.duckdb_arch }}.csv
            ${{ matrix.config.branch }}_non_matching_sha_${{ matrix.config.nightly_build }}_${{ matrix.config.duckdb_arch }}.csv
            ${{ matrix.config.branch }}_tested_platforms_${{ matrix.config.nightly_build }}_${{ matrix.config.duckdb_arch }}.csv
          if-no-files-found: ignore
    
  report:
    name: Create complete report
    runs-on: ubuntu-latest
    if: always()
    needs:
      - get-run-info 
      - run-tests
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_STAGING_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_STAGING_KEY }}
      AWS_DEFAULT_REGION: us-east-2
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository_owner }}/duckdb-build-status
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
            python-version: '3.11'

      - name: Install DuckDB for Python
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install duckdb pandas tabulate requests

      - name: Download inputs_${{ github.ref_name }}.json
        uses: actions/download-artifact@v4
        with:
          name: inputs_${{ github.ref_name }}.json
          path: .

      - name: Download extensions artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ${{ github.ref_name }}_ext*
          path: ${{ github.ref_name }}_failed_ext

      - name: Download duckdb file
        uses: actions/download-artifact@v4
        with:
          name: ${{ github.ref_name }}_run_info_tables.duckdb
          path: ${{ github.ref_name }}_tables
      
      - name: Generate report
        shell: bash
        env:
          CURR_DATE: ${{ needs.get-run-info.outputs.CURR_DATE }}
        run: |
          python scripts/create_build_report.py --branch ${{ github.ref_name }}

      - name: Upload REPORT
        uses: actions/upload-artifact@v4
        with:
          name: REPORT-${{ github.ref_name }}
          path: ${{ needs.get-run-info.outputs.CURR_DATE }}-${{ github.ref_name }}.md
          
      - name: Generate digests
        shell: bash
        run: |
          # get a run_id
          run_id=${{ needs.get-run-info.outputs.run_id }}
          # download nightly release files from GH and generate digests
          aws s3 ls --recursive s3://duckdb-staging/71c5c07cdd/v1.3.0/${{ env.GH_REPO }}/github_release | awk '{print $4}' > release-assets.txt 
          cat release-assets.txt
          for file_path in $(cat release-assets.txt); do 
            aws s3 cp s3://duckdb-staging/$file_path .;
            file=$(basename $file_path)
            shasum -a 256 $file >> ${{ needs.get-run-info.outputs.CURR_DATE }}_checksum_${{ github.ref_name }}.txt;
            rm $file; 
          done

      - name: Upload checksum file
        uses: actions/upload-artifact@v4
        with:
          name: CHECKSUM_${{ github.ref_name }}
          path: ${{ needs.get-run-info.outputs.CURR_DATE }}_checksum_${{ github.ref_name }}.txt

  push-reports:
    name: Push Reports
    if: ${{ inputs.should_publish == 'true' }}
    runs-on: ubuntu-latest
    needs: 
      - get-run-info
      - report
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository_owner }}/duckdb-build-status

      - name: Download Reports
        uses: actions/download-artifact@v4
        with:
          pattern: REPORT*
          path: .

      - name: Download checksum file
        uses: actions/download-artifact@v4
        with:
          pattern: CHECKSUM*
          path: .

      - name: Upload REPORT to the docs directory
        shell: bash
        env:
          CI_COMMIT_MESSAGE: "Add ${{ needs.get-run-info.outputs.CURR_DATE }} Reports"
          CI_COMMIT_AUTHOR: "hmeriann"
          CI_COMMIT_EMAIL: "zuleykha.pavlichenkova@gmail.com"
          GH_TOKEN: ${{ github.token }}
        run: |
          git config --global user.name ${{ env.CI_COMMIT_AUTHOR }}
          git config --global user.email ${{ env.CI_COMMIT_EMAIL }}
          
          # git config pull.rebase false
          # git pull origin main --allow-unrelated-histories

          mkdir -p docs/
          mkdir -p docs/${{ github.ref_name }}
          mkdir -p docs/${{ github.ref_name }}/checksum
          
          mv REPORT*/${{ needs.get-run-info.outputs.CURR_DATE }}-${{ github.ref_name }}.md docs/${{ github.ref_name }}/
          mv CHECKSUM*/${{ needs.get-run-info.outputs.CURR_DATE }}_checksum_${{ github.ref_name }}.txt docs/${{ github.ref_name }}/checksum

          ls -lah docs/${{ github.ref_name }}
          ls -lah docs/${{ github.ref_name }}/checksum

          git add docs/${{ github.ref_name }}/${{ needs.get-run-info.outputs.CURR_DATE }}-${{ github.ref_name }}.md
          git add docs/${{ github.ref_name }}/checksum/${{ needs.get-run-info.outputs.CURR_DATE }}_checksum_${{ github.ref_name }}.txt
          git commit -m "${{ env.CI_COMMIT_MESSAGE }}"
          git push origin ${{ github.ref_name }}

      - name: Checkout main
        if: ${{ github.ref_name != 'main'}}
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository_owner }}/duckdb-build-status
          ref: main
          
      - name: Push new report to main
        if: ${{ github.ref_name != 'main'}}
        shell: bash
        run: |
          report_file="docs/${{ github.ref_name }}/${{ needs.get-run-info.outputs.CURR_DATE }}-${{ github.ref_name }}.md"
          checksum_file="docs/${{ github.ref_name }}/checksum/${{ needs.get-run-info.outputs.CURR_DATE }}_checksum_${{ github.ref_name }}.txt"
          git fetch origin ${{ github.ref_name }}:${{ github.ref_name }}
          git checkout ${{ github.ref_name }} -- $report_file
          git checkout ${{ github.ref_name }} -- $checksum_file
          git add $report_file $checksum_file
          git commit -m "Adding $report_file and $checksum_file to main"
          git push origin main
